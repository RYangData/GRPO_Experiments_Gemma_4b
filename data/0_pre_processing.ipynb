{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contains 3037 examples\n"
     ]
    }
   ],
   "source": [
    "# 1. Load the data\n",
    "file_path = \"data/train.json\"\n",
    "with open(file_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(f\"Dataset contains {len(data)} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pre_text': ['26 | 2009 annual report in fiscal 2008 , revenues in the credit union systems and services business segment increased 14% ( 14 % ) from fiscal 2007 .',\n",
       "  'all revenue components within the segment experienced growth during fiscal 2008 .',\n",
       "  'license revenue generated the largest dollar growth in revenue as episys ae , our flagship core processing system aimed at larger credit unions , experienced strong sales throughout the year .',\n",
       "  'support and service revenue , which is the largest component of total revenues for the credit union segment , experienced 34 percent growth in eft support and 10 percent growth in in-house support .',\n",
       "  'gross profit in this business segment increased $ 9344 in fiscal 2008 compared to fiscal 2007 , due primarily to the increase in license revenue , which carries the highest margins .',\n",
       "  'liquidity and capital resources we have historically generated positive cash flow from operations and have generally used funds generated from operations and short-term borrowings on our revolving credit facility to meet capital requirements .',\n",
       "  'we expect this trend to continue in the future .',\n",
       "  'the company 2019s cash and cash equivalents increased to $ 118251 at june 30 , 2009 from $ 65565 at june 30 , 2008 .',\n",
       "  'the following table summarizes net cash from operating activities in the statement of cash flows : 2009 2008 2007 .'],\n",
       " 'post_text': ['year ended june 30 , cash provided by operations increased $ 25587 to $ 206588 for the fiscal year ended june 30 , 2009 as compared to $ 181001 for the fiscal year ended june 30 , 2008 .',\n",
       "  'this increase is primarily attributable to a decrease in receivables compared to the same period a year ago of $ 21214 .',\n",
       "  'this decrease is largely the result of fiscal 2010 annual software maintenance billings being provided to customers earlier than in the prior year , which allowed more cash to be collected before the end of the fiscal year than in previous years .',\n",
       "  'further , we collected more cash overall related to revenues that will be recognized in subsequent periods in the current year than in fiscal 2008 .',\n",
       "  'cash used in investing activities for the fiscal year ended june 2009 was $ 59227 and includes $ 3027 in contingent consideration paid on prior years 2019 acquisitions .',\n",
       "  'cash used in investing activities for the fiscal year ended june 2008 was $ 102148 and includes payments for acquisitions of $ 48109 , plus $ 1215 in contingent consideration paid on prior years 2019 acquisitions .',\n",
       "  'capital expenditures for fiscal 2009 were $ 31562 compared to $ 31105 for fiscal 2008 .',\n",
       "  'cash used for software development in fiscal 2009 was $ 24684 compared to $ 23736 during the prior year .',\n",
       "  'net cash used in financing activities for the current fiscal year was $ 94675 and includes the repurchase of 3106 shares of our common stock for $ 58405 , the payment of dividends of $ 26903 and $ 13489 net repayment on our revolving credit facilities .',\n",
       "  'cash used in financing activities was partially offset by proceeds of $ 3773 from the exercise of stock options and the sale of common stock ( through the employee stock purchase plan ) and $ 348 excess tax benefits from stock option exercises .',\n",
       "  'during fiscal 2008 , net cash used in financing activities for the fiscal year was $ 101905 and includes the repurchase of 4200 shares of our common stock for $ 100996 , the payment of dividends of $ 24683 and $ 429 net repayment on our revolving credit facilities .',\n",
       "  'cash used in financing activities was partially offset by proceeds of $ 20394 from the exercise of stock options and the sale of common stock and $ 3809 excess tax benefits from stock option exercises .',\n",
       "  'beginning during fiscal 2008 , us financial markets and many of the largest us financial institutions have been shaken by negative developments in the home mortgage industry and the mortgage markets , and particularly the markets for subprime mortgage-backed securities .',\n",
       "  'since that time , these and other such developments have resulted in a broad , global economic downturn .',\n",
       "  'while we , as is the case with most companies , have experienced the effects of this downturn , we have not experienced any significant issues with our current collection efforts , and we believe that any future impact to our liquidity will be minimized by cash generated by recurring sources of revenue and due to our access to available lines of credit. .'],\n",
       " 'filename': 'JKHY/2009/page_28.pdf',\n",
       " 'table_ori': [['', 'Year ended June 30, 2009'],\n",
       "  ['2008', '2007'],\n",
       "  ['Net income', '$103,102', '$104,222', '$104,681'],\n",
       "  ['Non-cash expenses', '74,397', '70,420', '56,348'],\n",
       "  ['Change in receivables', '21,214', '(2,913)', '(28,853)'],\n",
       "  ['Change in deferred revenue', '21,943', '5,100', '24,576'],\n",
       "  ['Change in other assets and liabilities', '(14,068)', '4,172', '17,495'],\n",
       "  ['Net cash from operating activities', '$206,588', '$181,001', '$174,247']],\n",
       " 'table': [['2008',\n",
       "   'year ended june 30 2009 2008',\n",
       "   'year ended june 30 2009 2008',\n",
       "   'year ended june 30 2009'],\n",
       "  ['net income', '$ 103102', '$ 104222', '$ 104681'],\n",
       "  ['non-cash expenses', '74397', '70420', '56348'],\n",
       "  ['change in receivables', '21214', '-2913 ( 2913 )', '-28853 ( 28853 )'],\n",
       "  ['change in deferred revenue', '21943', '5100', '24576'],\n",
       "  ['change in other assets and liabilities',\n",
       "   '-14068 ( 14068 )',\n",
       "   '4172',\n",
       "   '17495'],\n",
       "  ['net cash from operating activities', '$ 206588', '$ 181001', '$ 174247']],\n",
       " 'qa': {'question': 'what was the percentage change in the net cash from operating activities from 2008 to 2009',\n",
       "  'answer': '14.1%',\n",
       "  'explanation': '',\n",
       "  'ann_table_rows': [6],\n",
       "  'ann_text_rows': [],\n",
       "  'steps': [{'op': 'minus2-1',\n",
       "    'arg1': '206588',\n",
       "    'arg2': '181001',\n",
       "    'res': '25587'},\n",
       "   {'op': 'divide2-2', 'arg1': '#0', 'arg2': '181001', 'res': '14.1%'}],\n",
       "  'program': 'subtract(206588, 181001), divide(#0, 181001)',\n",
       "  'gold_inds': {'table_6': '2008 the net cash from operating activities of year ended june 30 2009 2008 is $ 206588 ; the net cash from operating activities of year ended june 30 2009 2008 is $ 181001 ; the net cash from operating activities of year ended june 30 2009 is $ 174247 ;'},\n",
       "  'exe_ans': 0.14136,\n",
       "  'program_re': 'divide(subtract(206588, 181001), 181001)'},\n",
       " 'id': 'Single_JKHY/2009/page_28.pdf-3',\n",
       " 'annotation': {'amt_table': \"<table class='wikitable'><tr><td>1</td><td>2008</td><td>year ended june 30 2009 2008</td><td>year ended june 30 2009 2008</td><td>year ended june 30 2009</td></tr><tr><td>2</td><td>net income</td><td>$ 103102</td><td>$ 104222</td><td>$ 104681</td></tr><tr><td>3</td><td>non-cash expenses</td><td>74397</td><td>70420</td><td>56348</td></tr><tr><td>4</td><td>change in receivables</td><td>21214</td><td>-2913 ( 2913 )</td><td>-28853 ( 28853 )</td></tr><tr><td>5</td><td>change in deferred revenue</td><td>21943</td><td>5100</td><td>24576</td></tr><tr><td>6</td><td>change in other assets and liabilities</td><td>-14068 ( 14068 )</td><td>4172</td><td>17495</td></tr><tr><td>7</td><td>net cash from operating activities</td><td>$ 206588</td><td>$ 181001</td><td>$ 174247</td></tr></table>\",\n",
       "  'amt_pre_text': '26 | 2009 annual report in fiscal 2008 , revenues in the credit union systems and services business segment increased 14% ( 14 % ) from fiscal 2007 . all revenue components within the segment experienced growth during fiscal 2008 . license revenue generated the largest dollar growth in revenue as episys ae , our flagship core processing system aimed at larger credit unions , experienced strong sales throughout the year . support and service revenue , which is the largest component of total revenues for the credit union segment , experienced 34 percent growth in eft support and 10 percent growth in in-house support . gross profit in this business segment increased $ 9344 in fiscal 2008 compared to fiscal 2007 , due primarily to the increase in license revenue , which carries the highest margins . liquidity and capital resources we have historically generated positive cash flow from operations and have generally used funds generated from operations and short-term borrowings on our revolving credit facility to meet capital requirements . we expect this trend to continue in the future . the company 2019s cash and cash equivalents increased to $ 118251 at june 30 , 2009 from $ 65565 at june 30 , 2008 . the following table summarizes net cash from operating activities in the statement of cash flows : 2009 2008 2007 .',\n",
       "  'amt_post_text': 'year ended june 30 , cash provided by operations increased $ 25587 to $ 206588 for the fiscal year ended june 30 , 2009 as compared to $ 181001 for the fiscal year ended june 30 , 2008 . this increase is primarily attributable to a decrease in receivables compared to the same period a year ago of $ 21214 . this decrease is largely the result of fiscal 2010 annual software maintenance billings being provided to customers earlier than in the prior year , which allowed more cash to be collected before the end of the fiscal year than in previous years . further , we collected more cash overall related to revenues that will be recognized in subsequent periods in the current year than in fiscal 2008 . cash used in investing activities for the fiscal year ended june 2009 was $ 59227 and includes $ 3027 in contingent consideration paid on prior years 2019 acquisitions . cash used in investing activities for the fiscal year ended june 2008 was $ 102148 and includes payments for acquisitions of $ 48109 , plus $ 1215 in contingent consideration paid on prior years 2019 acquisitions . capital expenditures for fiscal 2009 were $ 31562 compared to $ 31105 for fiscal 2008 . cash used for software development in fiscal 2009 was $ 24684 compared to $ 23736 during the prior year . net cash used in financing activities for the current fiscal year was $ 94675 and includes the repurchase of 3106 shares of our common stock for $ 58405 , the payment of dividends of $ 26903 and $ 13489 net repayment on our revolving credit facilities . cash used in financing activities was partially offset by proceeds of $ 3773 from the exercise of stock options and the sale of common stock ( through the employee stock purchase plan ) and $ 348 excess tax benefits from stock option exercises . during fiscal 2008 , net cash used in financing activities for the fiscal year was $ 101905 and includes the repurchase of 4200 shares of our common stock for $ 100996 , the payment of dividends of $ 24683 and $ 429 net repayment on our revolving credit facilities . cash used in financing activities was partially offset by proceeds of $ 20394 from the exercise of stock options and the sale of common stock and $ 3809 excess tax benefits from stock option exercises . beginning during fiscal 2008 , us financial markets and many of the largest us financial institutions have been shaken by negative developments in the home mortgage industry and the mortgage markets , and particularly the markets for subprime mortgage-backed securities . since that time , these and other such developments have resulted in a broad , global economic downturn . while we , as is the case with most companies , have experienced the effects of this downturn , we have not experienced any significant issues with our current collection efforts , and we believe that any future impact to our liquidity will be minimized by cash generated by recurring sources of revenue and due to our access to available lines of credit. .',\n",
       "  'original_program': 'subtract(206588, 181001), divide(A0, 181001)',\n",
       "  'step_list': ['Ask for number 206588',\n",
       "   'Ask for number 181001',\n",
       "   'subtract(206588, 181001)',\n",
       "   'divide(A0, 181001)'],\n",
       "  'answer_list': ['206588', '181001', 'A0', 'A1'],\n",
       "  'dialogue_break': ['what is the net cash from operating activities in 2009?',\n",
       "   'what about in 2008?',\n",
       "   'what is the difference?',\n",
       "   'what percentage change does this represent?'],\n",
       "  'turn_program_ori': ['206588',\n",
       "   '181001',\n",
       "   'subtract(206588, 181001)',\n",
       "   'subtract(206588, 181001), divide(#0, 181001)'],\n",
       "  'dialogue_break_ori': ['what is the net cash from operating activities in 2009?',\n",
       "   'what about in 2008?',\n",
       "   'what is the difference?',\n",
       "   'what percentage change does this represent?'],\n",
       "  'turn_program': ['206588',\n",
       "   '181001',\n",
       "   'subtract(206588, 181001)',\n",
       "   'subtract(206588, 181001), divide(#0, 181001)'],\n",
       "  'qa_split': [0, 0, 0, 0],\n",
       "  'exe_ans_list': [206588.0, 181001.0, 25587.0, 0.14136]}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: 3037 examples\n",
      "Dev dataset: 421 examples\n",
      "\n",
      "Examining dev data structure...\n",
      "Keys at root level and their frequency:\n",
      "pre_text: 421 (100.00%)\n",
      "post_text: 421 (100.00%)\n",
      "filename: 421 (100.00%)\n",
      "table_ori: 421 (100.00%)\n",
      "table: 421 (100.00%)\n",
      "id: 421 (100.00%)\n",
      "annotation: 421 (100.00%)\n",
      "qa: 300 (71.26%)\n",
      "qa_0: 121 (28.74%)\n",
      "qa_1: 121 (28.74%)\n",
      "\n",
      "Dev sample data structures:\n",
      "\n",
      "Sample 1 keys: ['pre_text', 'post_text', 'filename', 'table_ori', 'table', 'qa', 'id', 'annotation']\n",
      "  'qa' keys: ['question', 'answer', 'explanation', 'ann_table_rows', 'ann_text_rows', 'steps', 'program', 'gold_inds', 'exe_ans', 'program_re']\n",
      "\n",
      "Sample 2 keys: ['pre_text', 'post_text', 'filename', 'table_ori', 'table', 'id', 'annotation', 'qa_0', 'qa_1']\n",
      "  Found multiple QA keys: ['qa_0', 'qa_1']\n",
      "  'qa_0' keys: ['question', 'answer', 'explanation', 'ann_table_rows', 'ann_text_rows', 'steps', 'program', 'gold_inds', 'exe_ans', 'program_re']\n",
      "\n",
      "=== COMPARATIVE STATISTICS ===\n",
      "Statistic                      Train           Dev            \n",
      "------------------------------------------------------------\n",
      "Total examples                 3037            421            \n",
      "Examples with qa               2109            300            \n",
      "Examples with qa_n             928             121            \n",
      "\n",
      "--- Question & Answer ---\n",
      "Mean question length           16.27           16.54\n",
      "\n",
      "--- Answer Types ---\n",
      "Percentage                     87.49%          88.12%\n",
      "Currency                       1.22%          0.24%\n",
      "Decimal                        82.25%          80.05%\n",
      "\n",
      "--- Reasoning Steps ---\n",
      "Mean steps per question        1.85           1.87\n",
      "Max steps per question         5           5\n",
      "\n",
      "--- Table Size ---\n",
      "Mean table rows                6.37           6.32\n",
      "Mean table columns             3.84           4.03\n",
      "\n",
      "--- Dialogue ---\n",
      "Mean dialogue turns            3.66           3.54\n",
      "\n",
      "=== TOP OPERATIONS COMPARISON ===\n",
      "Operation       Train %         Dev %           Difference     \n",
      "------------------------------------------------------------\n",
      "divide1-2       15.49%           16.44%           +0.95%\n",
      "minus1-1        15.31%           17.32%           +2.01%\n",
      "divide2-2       13.42%           12.99%           -0.43%\n",
      "minus2-1        13.03%           12.50%           -0.53%\n",
      "divide1-1       6.90%           6.30%           -0.60%\n",
      "divide2-1       5.09%           6.40%           +1.30%\n",
      "add1-1          5.15%           3.54%           -1.60%\n",
      "add2-1          4.32%           3.64%           -0.67%\n",
      "add1-2          2.81%           2.56%           -0.25%\n",
      "add2-2          2.25%           2.07%           -0.19%\n",
      "\n",
      "=== DATA OVERLAP ANALYSIS ===\n",
      "Question overlap: 9 questions (1.97% of dev)\n",
      "Document overlap: 0 files (0.00% of dev)\n",
      "\n",
      "Sample overlapping questions:\n",
      "- what is the tax expense related to discontinued operations in 2012?\n",
      "- what was the percentage change in free cash flow from 2013 to 2014?\n",
      "- what is the tax expense related to discontinued operations in 2013?\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load both datasets\n",
    "train_path = \"data/train.json\"\n",
    "dev_path = \"data/dev.json\"\n",
    "\n",
    "with open(train_path, 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "    \n",
    "with open(dev_path, 'r') as f:\n",
    "    dev_data = json.load(f)\n",
    "\n",
    "print(f\"Train dataset: {len(train_data)} examples\")\n",
    "print(f\"Dev dataset: {len(dev_data)} examples\")\n",
    "\n",
    "# Examine the structure of dev dataset\n",
    "print(\"\\nExamining dev data structure...\")\n",
    "dev_keys_at_root = Counter()\n",
    "for ex in dev_data:\n",
    "    for key in ex.keys():\n",
    "        dev_keys_at_root[key] += 1\n",
    "\n",
    "print(\"Keys at root level and their frequency:\")\n",
    "for key, count in dev_keys_at_root.most_common():\n",
    "    print(f\"{key}: {count} ({count/len(dev_data)*100:.2f}%)\")\n",
    "\n",
    "# Sample data structure\n",
    "def print_sample_structure(data, dataset_name, num_samples=2):\n",
    "    print(f\"\\n{dataset_name} sample data structures:\")\n",
    "    for i, ex in enumerate(data[:num_samples]):\n",
    "        print(f\"\\nSample {i+1} keys: {list(ex.keys())}\")\n",
    "        if 'qa' in ex:\n",
    "            print(f\"  'qa' keys: {list(ex['qa'].keys())}\")\n",
    "        elif any(k.startswith('qa_') for k in ex.keys()):\n",
    "            qa_keys = [k for k in ex.keys() if k.startswith('qa_')]\n",
    "            print(f\"  Found multiple QA keys: {qa_keys}\")\n",
    "            if qa_keys:\n",
    "                print(f\"  '{qa_keys[0]}' keys: {list(ex[qa_keys[0]].keys())}\")\n",
    "\n",
    "print_sample_structure(dev_data, \"Dev\")\n",
    "\n",
    "# Functions for analysis (reusing from before but with additional comparison capabilities)\n",
    "def analyze_dataset(data, dataset_name):\n",
    "    \"\"\"Analyze a dataset and return key statistics\"\"\"\n",
    "    \n",
    "    # Basic counts\n",
    "    total_examples = len(data)\n",
    "    examples_with_qa = sum(1 for ex in data if 'qa' in ex)\n",
    "    examples_with_qa_n = sum(1 for ex in data if any(k.startswith('qa_') for k in ex.keys()))\n",
    "    \n",
    "    # Extract QA data\n",
    "    qa_list = []\n",
    "    for ex in data:\n",
    "        if 'qa' in ex:\n",
    "            qa_list.append(ex['qa'])\n",
    "        else:\n",
    "            for key in [k for k in ex.keys() if k.startswith('qa_')]:\n",
    "                if key in ex and isinstance(ex[key], dict):\n",
    "                    qa_list.append(ex[key])\n",
    "    \n",
    "    # QA stats\n",
    "    questions = [qa.get('question', '') for qa in qa_list if qa]\n",
    "    question_lengths = [len(q.split()) for q in questions if q]\n",
    "    \n",
    "    answers = [qa.get('answer', '') for qa in qa_list if qa]\n",
    "    answer_types = {\n",
    "        'percentage': sum('%' in str(a) for a in answers),\n",
    "        'currency': sum('$' in str(a) for a in answers),\n",
    "        'decimal': sum('.' in str(a) for a in answers)\n",
    "    }\n",
    "    \n",
    "    # Steps and operations\n",
    "    all_steps = []\n",
    "    all_operations = []\n",
    "    for qa in qa_list:\n",
    "        if 'steps' in qa and qa['steps']:\n",
    "            steps = qa['steps']\n",
    "            all_steps.append(len(steps))\n",
    "            all_operations.extend([step.get('op', '') for step in steps])\n",
    "    \n",
    "    # Table stats\n",
    "    table_rows = [len(ex.get('table', [])) for ex in data]\n",
    "    table_cols = [len(ex.get('table', [[]])[0]) if ex.get('table') and len(ex.get('table', [[]])) > 0 else 0 \n",
    "                  for ex in data]\n",
    "    \n",
    "    # Dialogue stats\n",
    "    dialogue_turns = []\n",
    "    for ex in data:\n",
    "        if 'annotation' in ex and 'dialogue_break' in ex['annotation']:\n",
    "            dialogue_turns.append(len(ex['annotation']['dialogue_break']))\n",
    "    \n",
    "    return {\n",
    "        'dataset_name': dataset_name,\n",
    "        'total_examples': total_examples,\n",
    "        'qa_examples': examples_with_qa,\n",
    "        'qa_n_examples': examples_with_qa_n,\n",
    "        'question_lengths': {\n",
    "            'mean': np.mean(question_lengths) if question_lengths else 0,\n",
    "            'min': min(question_lengths) if question_lengths else 0,\n",
    "            'max': max(question_lengths) if question_lengths else 0\n",
    "        },\n",
    "        'answer_types': answer_types,\n",
    "        'steps_count': {\n",
    "            'mean': np.mean(all_steps) if all_steps else 0,\n",
    "            'min': min(all_steps) if all_steps else 0,\n",
    "            'max': max(all_steps) if all_steps else 0\n",
    "        },\n",
    "        'operation_counts': Counter(all_operations),\n",
    "        'table_size': {\n",
    "            'rows_mean': np.mean(table_rows) if table_rows else 0,\n",
    "            'rows_max': max(table_rows) if table_rows else 0,\n",
    "            'cols_mean': np.mean(table_cols) if table_cols else 0,\n",
    "            'cols_max': max(table_cols) if table_cols else 0\n",
    "        },\n",
    "        'dialogue_turns': {\n",
    "            'mean': np.mean(dialogue_turns) if dialogue_turns else 0,\n",
    "            'min': min(dialogue_turns) if dialogue_turns else 0,\n",
    "            'max': max(dialogue_turns) if dialogue_turns else 0\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Analyze both datasets\n",
    "train_stats = analyze_dataset(train_data, \"Train\")\n",
    "dev_stats = analyze_dataset(dev_data, \"Dev\")\n",
    "\n",
    "# Print comparative statistics\n",
    "def print_comparative_stats(train_stats, dev_stats):\n",
    "    print(\"\\n=== COMPARATIVE STATISTICS ===\")\n",
    "    print(f\"{'Statistic':<30} {'Train':<15} {'Dev':<15}\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{'Total examples':<30} {train_stats['total_examples']:<15} {dev_stats['total_examples']:<15}\")\n",
    "    print(f\"{'Examples with qa':<30} {train_stats['qa_examples']:<15} {dev_stats['qa_examples']:<15}\")\n",
    "    print(f\"{'Examples with qa_n':<30} {train_stats['qa_n_examples']:<15} {dev_stats['qa_n_examples']:<15}\")\n",
    "    \n",
    "    print(\"\\n--- Question & Answer ---\")\n",
    "    print(f\"{'Mean question length':<30} {train_stats['question_lengths']['mean']:.2f}{'':<10} {dev_stats['question_lengths']['mean']:.2f}\")\n",
    "    \n",
    "    print(\"\\n--- Answer Types ---\")\n",
    "    for answer_type in ['percentage', 'currency', 'decimal']:\n",
    "        train_pct = train_stats['answer_types'][answer_type] / train_stats['total_examples'] * 100\n",
    "        dev_pct = dev_stats['answer_types'][answer_type] / dev_stats['total_examples'] * 100\n",
    "        print(f\"{answer_type.capitalize():<30} {train_pct:.2f}%{'':<9} {dev_pct:.2f}%\")\n",
    "    \n",
    "    print(\"\\n--- Reasoning Steps ---\")\n",
    "    print(f\"{'Mean steps per question':<30} {train_stats['steps_count']['mean']:.2f}{'':<10} {dev_stats['steps_count']['mean']:.2f}\")\n",
    "    print(f\"{'Max steps per question':<30} {train_stats['steps_count']['max']}{'':<10} {dev_stats['steps_count']['max']}\")\n",
    "    \n",
    "    print(\"\\n--- Table Size ---\")\n",
    "    print(f\"{'Mean table rows':<30} {train_stats['table_size']['rows_mean']:.2f}{'':<10} {dev_stats['table_size']['rows_mean']:.2f}\")\n",
    "    print(f\"{'Mean table columns':<30} {train_stats['table_size']['cols_mean']:.2f}{'':<10} {dev_stats['table_size']['cols_mean']:.2f}\")\n",
    "    \n",
    "    print(\"\\n--- Dialogue ---\")\n",
    "    print(f\"{'Mean dialogue turns':<30} {train_stats['dialogue_turns']['mean']:.2f}{'':<10} {dev_stats['dialogue_turns']['mean']:.2f}\")\n",
    "\n",
    "print_comparative_stats(train_stats, dev_stats)\n",
    "\n",
    "# Compare top operations\n",
    "def compare_operations(train_stats, dev_stats):\n",
    "    print(\"\\n=== TOP OPERATIONS COMPARISON ===\")\n",
    "    train_ops = train_stats['operation_counts']\n",
    "    dev_ops = dev_stats['operation_counts']\n",
    "    \n",
    "    # Get all unique operations\n",
    "    all_ops = set(list(train_ops.keys()) + list(dev_ops.keys()))\n",
    "    \n",
    "    # Calculate percentages\n",
    "    train_total = sum(train_ops.values())\n",
    "    dev_total = sum(dev_ops.values())\n",
    "    \n",
    "    print(f\"{'Operation':<15} {'Train %':<15} {'Dev %':<15} {'Difference':<15}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Sort by total frequency\n",
    "    sorted_ops = sorted(all_ops, key=lambda op: (train_ops.get(op, 0) + dev_ops.get(op, 0)), reverse=True)\n",
    "    \n",
    "    for op in sorted_ops[:10]:  # Top 10 operations\n",
    "        train_pct = train_ops.get(op, 0) / train_total * 100 if train_total else 0\n",
    "        dev_pct = dev_ops.get(op, 0) / dev_total * 100 if dev_total else 0\n",
    "        diff = dev_pct - train_pct\n",
    "        \n",
    "        print(f\"{op:<15} {train_pct:.2f}%{'':<10} {dev_pct:.2f}%{'':<10} {diff:+.2f}%\")\n",
    "\n",
    "compare_operations(train_stats, dev_stats)\n",
    "\n",
    "# Check for potential data leakage/overlap\n",
    "def check_overlap(train_data, dev_data):\n",
    "    print(\"\\n=== DATA OVERLAP ANALYSIS ===\")\n",
    "    \n",
    "    # Check question overlap\n",
    "    train_questions = set()\n",
    "    dev_questions = set()\n",
    "    \n",
    "    for ex in train_data:\n",
    "        if 'qa' in ex and 'question' in ex['qa']:\n",
    "            train_questions.add(ex['qa']['question'])\n",
    "        for key in [k for k in ex.keys() if k.startswith('qa_')]:\n",
    "            if key in ex and 'question' in ex[key]:\n",
    "                train_questions.add(ex[key]['question'])\n",
    "    \n",
    "    for ex in dev_data:\n",
    "        if 'qa' in ex and 'question' in ex['qa']:\n",
    "            dev_questions.add(ex['qa']['question'])\n",
    "        for key in [k for k in ex.keys() if k.startswith('qa_')]:\n",
    "            if key in ex and 'question' in ex[key]:\n",
    "                dev_questions.add(ex[key]['question'])\n",
    "    \n",
    "    question_overlap = train_questions.intersection(dev_questions)\n",
    "    \n",
    "    # Check file/document overlap\n",
    "    train_files = set(ex.get('filename', '') for ex in train_data)\n",
    "    dev_files = set(ex.get('filename', '') for ex in dev_data)\n",
    "    file_overlap = train_files.intersection(dev_files)\n",
    "    \n",
    "    print(f\"Question overlap: {len(question_overlap)} questions ({len(question_overlap)/len(dev_questions)*100:.2f}% of dev)\")\n",
    "    print(f\"Document overlap: {len(file_overlap)} files ({len(file_overlap)/len(dev_files)*100:.2f}% of dev)\")\n",
    "    \n",
    "    if len(question_overlap) > 0:\n",
    "        print(\"\\nSample overlapping questions:\")\n",
    "        for q in list(question_overlap)[:3]:\n",
    "            print(f\"- {q}\")\n",
    "\n",
    "check_overlap(train_data, dev_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-question Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example ID: Double_UPS/2009/page_33.pdf\n",
      "\n",
      "Source: UPS/2009/page_33.pdf\n",
      "\n",
      "Question 1: what is the roi of an investment in ups in 2004 and sold in 2006?\n",
      "Answer 1: -8.9%\n",
      "\n",
      "Question 2: what was the difference in percentage cumulative return on investment for united parcel service inc . compared to the s&p 500 index for the five year period ended 12/31/09?\n",
      "Answer 2: -26.16%\n",
      "\n",
      "Dialogue structure:\n",
      "Turn 1: what was the fluctuation of the performance price of the ups from 2004 to 2006?\n",
      "Turn 2: and how much does this fluctuation represent in relation to that price in 2004?\n",
      "Turn 3: and from this year to 2009, what was the fluctuation for that stock?\n",
      "Turn 4: what is this fluctuation as a percentage of the 2004 price?\n",
      "Turn 5: and for the s&p 500 index price, what was the fluctuation in those five years?\n",
      "Turn 6: and what percentage does this fluctuation represent in relation to the 2004 price of this stock?\n",
      "Turn 7: what is, then, the difference between the ups percentage and this s&p 500 index one, for this five year period?\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the data\n",
    "file_path = \"/Users/richardyang/Desktop/Long Term Career/UK 2025 Cases/TomoroAI/FinQA_Experim/data/data/train.json\"\n",
    "with open(file_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Find a multi-QA example\n",
    "multi_qa_example = None\n",
    "for example in data:\n",
    "    if 'qa_0' in example and 'qa_1' in example:\n",
    "        multi_qa_example = example\n",
    "        break\n",
    "\n",
    "if multi_qa_example:\n",
    "    print(\"Example ID:\", multi_qa_example.get('id', 'Unknown'))\n",
    "    print(\"\\nSource:\", multi_qa_example.get('filename', 'Unknown'))\n",
    "    \n",
    "    # Print the questions and answers\n",
    "    print(\"\\nQuestion 1:\", multi_qa_example['qa_0']['question'])\n",
    "    print(\"Answer 1:\", multi_qa_example['qa_0']['answer'])\n",
    "    \n",
    "    print(\"\\nQuestion 2:\", multi_qa_example['qa_1']['question'])\n",
    "    print(\"Answer 2:\", multi_qa_example['qa_1']['answer'])\n",
    "    \n",
    "    # Print the dialogue structure if available\n",
    "    if 'dialogue_break_ori' in multi_qa_example.get('annotation', {}):\n",
    "        print(\"\\nDialogue structure:\")\n",
    "        for i, turn in enumerate(multi_qa_example['annotation']['dialogue_break_ori']):\n",
    "            print(f\"Turn {i+1}: {turn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the datasets for Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3037 training examples and 421 dev examples\n",
      "Processing datasets...\n",
      "\n",
      "Processed 4507 examples for Objective A (Final Answer Only)\n",
      "  - Train: 3965 examples\n",
      "  - Dev: 542 examples\n",
      "\n",
      "Processed 4507 examples for Objective B (Program + Answer)\n",
      "  - Train: 3965 examples\n",
      "  - Dev: 542 examples\n",
      "\n",
      "All processed datasets saved to data/processed_datasets\n"
     ]
    }
   ],
   "source": [
    "with open(train_path, 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "    \n",
    "with open(dev_path, 'r') as f:\n",
    "    dev_data = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(train_data)} training examples and {len(dev_data)} dev examples\")\n",
    "\n",
    "# Helper functions\n",
    "def format_table_to_text(table: list[list[str]]) -> str:\n",
    "    \"\"\"Convert table to a readable text format\"\"\"\n",
    "    if not table or len(table) == 0:\n",
    "        return \"\"\n",
    "    \n",
    "    formatted_rows = []\n",
    "    \n",
    "    # Add header\n",
    "    header = \" | \".join(str(cell) for cell in table[0])\n",
    "    formatted_rows.append(header)\n",
    "    formatted_rows.append(\"-\" * len(header))  # separator line\n",
    "    \n",
    "    # Add data rows\n",
    "    for row in table[1:]:\n",
    "        formatted_rows.append(\" | \".join(str(cell) for cell in row))\n",
    "    \n",
    "    return \"\\n\".join(formatted_rows)\n",
    "\n",
    "def clean_text(text_list: list[str]) -> str:\n",
    "    \"\"\"Clean and join text segments\"\"\"\n",
    "    if not text_list:\n",
    "        return \"\"\n",
    "    return \" \".join([re.sub(r'\\s+', ' ', segment.strip()) for segment in text_list])\n",
    "\n",
    "def format_program_steps(steps: list[dict]) -> str:\n",
    "    \"\"\"Format program steps into a human-readable chain of thought\"\"\"\n",
    "    if not steps:\n",
    "        return \"\"\n",
    "    \n",
    "    formatted_steps = []\n",
    "    \n",
    "    for i, step in enumerate(steps, 1):\n",
    "        operation = step.get('op', '')\n",
    "        arg1 = step.get('arg1', '')\n",
    "        arg2 = step.get('arg2', '')\n",
    "        result = step.get('res', '')\n",
    "        \n",
    "        # Clean up operation name for readability\n",
    "        op_name = operation\n",
    "        if operation.startswith('divide'):\n",
    "            op_name = 'divide'\n",
    "        elif operation.startswith('minus'):\n",
    "            op_name = 'subtract'\n",
    "        elif operation.startswith('add'):\n",
    "            op_name = 'add'\n",
    "        elif operation.startswith('multiply'):\n",
    "            op_name = 'multiply'\n",
    "            \n",
    "        formatted_step = f\"Step {i}: {op_name}({arg1}, {arg2}) = {result}\"\n",
    "        formatted_steps.append(formatted_step)\n",
    "        \n",
    "    return \"\\n\".join(formatted_steps)\n",
    "\n",
    "def get_qa_pairs(example: dict) -> list[dict]:\n",
    "    \"\"\"Extract all QA pairs from an example (handles both single and multi-QA formats)\"\"\"\n",
    "    qa_pairs = []\n",
    "    \n",
    "    # Handle regular QA\n",
    "    if 'qa' in example and isinstance(example['qa'], dict):\n",
    "        qa_pairs.append(example['qa'])\n",
    "    \n",
    "    # Handle multi-QA (qa_0, qa_1, etc.)\n",
    "    qa_indices = sorted([int(k[3:]) for k in example.keys() if k.startswith('qa_') and k[3:].isdigit()])\n",
    "    for idx in qa_indices:\n",
    "        key = f'qa_{idx}'\n",
    "        if key in example and isinstance(example[key], dict):\n",
    "            qa_pairs.append(example[key])\n",
    "    \n",
    "    return qa_pairs\n",
    "\n",
    "# Process function for Objective A (Final Answer Only)\n",
    "def process_for_final_answer(data: list[dict], split_name: str) -> pd.DataFrame:\n",
    "    \"\"\"Process data for the final answer only objective\"\"\"\n",
    "    processed_data = []\n",
    "    \n",
    "    for example in data:\n",
    "        # Get context elements\n",
    "        pre_text = clean_text(example.get('pre_text', []))\n",
    "        post_text = clean_text(example.get('post_text', []))\n",
    "        table_text = format_table_to_text(example.get('table', []))\n",
    "        example_id = example.get('id', '')\n",
    "        \n",
    "        # Get all QA pairs\n",
    "        qa_pairs = get_qa_pairs(example)\n",
    "        \n",
    "        for qa_idx, qa in enumerate(qa_pairs):\n",
    "            if not qa or 'question' not in qa or 'answer' not in qa:\n",
    "                continue\n",
    "                \n",
    "            question = qa['question']\n",
    "            answer = qa['answer']\n",
    "            \n",
    "            # Create prompt\n",
    "            prompt = f\"\"\"### Context:\n",
    "{pre_text}\n",
    "\n",
    "### Table:\n",
    "{table_text}\n",
    "\n",
    "### Additional Context:\n",
    "{post_text}\n",
    "\n",
    "### Question:\n",
    "{question}\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "            \n",
    "            # Create unique ID for this QA pair\n",
    "            qa_id = f\"{example_id}_{qa_idx}\" if qa_idx > 0 else example_id\n",
    "            \n",
    "            processed_data.append({\n",
    "                'prompt': prompt,\n",
    "                'answer': answer,\n",
    "                'id': qa_id,\n",
    "                'split': split_name\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(processed_data)\n",
    "\n",
    "# Process function for Objective B (Program + Answer)\n",
    "def process_for_program_answer(data: list[dict], split_name: str) -> pd.DataFrame:\n",
    "    \"\"\"Process data for the program + answer objective\"\"\"\n",
    "    processed_data = []\n",
    "    \n",
    "    for example in data:\n",
    "        # Get context elements\n",
    "        pre_text = clean_text(example.get('pre_text', []))\n",
    "        post_text = clean_text(example.get('post_text', []))\n",
    "        table_text = format_table_to_text(example.get('table', []))\n",
    "        example_id = example.get('id', '')\n",
    "        \n",
    "        # Get all QA pairs\n",
    "        qa_pairs = get_qa_pairs(example)\n",
    "        \n",
    "        for qa_idx, qa in enumerate(qa_pairs):\n",
    "            if not qa or 'question' not in qa or 'answer' not in qa or 'steps' not in qa:\n",
    "                continue\n",
    "                \n",
    "            question = qa['question']\n",
    "            answer = qa['answer']\n",
    "            steps = qa['steps']\n",
    "            \n",
    "            # Create prompt\n",
    "            prompt = f\"\"\"### Context:\n",
    "{pre_text}\n",
    "\n",
    "### Table:\n",
    "{table_text}\n",
    "\n",
    "### Additional Context:\n",
    "{post_text}\n",
    "\n",
    "### Question:\n",
    "{question}\n",
    "\n",
    "### Response:\n",
    "<think>\n",
    "\"\"\"\n",
    "            \n",
    "            # Format program steps\n",
    "            program_text = format_program_steps(steps)\n",
    "            full_output = f\"\"\"{program_text}\n",
    "</think>\n",
    "Final Answer: {answer}\"\"\"\n",
    "            \n",
    "            # Create unique ID for this QA pair\n",
    "            qa_id = f\"{example_id}_{qa_idx}\" if qa_idx > 0 else example_id\n",
    "            \n",
    "            processed_data.append({\n",
    "                'prompt': prompt,\n",
    "                'output': full_output,\n",
    "                'id': qa_id,\n",
    "                'split': split_name\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(processed_data)\n",
    "\n",
    "# Process both datasets for both objectives\n",
    "print(\"Processing datasets...\")\n",
    "\n",
    "# Objective A: Final Answer Only\n",
    "train_final_answer = process_for_final_answer(train_data, \"train\")\n",
    "dev_final_answer = process_for_final_answer(dev_data, \"dev\")\n",
    "final_answer_df = pd.concat([train_final_answer, dev_final_answer])\n",
    "\n",
    "# Objective B: Program + Answer\n",
    "train_program_answer = process_for_program_answer(train_data, \"train\")\n",
    "dev_program_answer = process_for_program_answer(dev_data, \"dev\")\n",
    "program_answer_df = pd.concat([train_program_answer, dev_program_answer])\n",
    "\n",
    "# Create output directory\n",
    "output_dir = Path(\"data/processed_datasets\")\n",
    "output_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Save datasets\n",
    "final_answer_df.to_csv(output_dir / \"finqa_final_answer.csv\", index=False)\n",
    "final_answer_df.to_json(output_dir / \"finqa_final_answer.jsonl\", orient='records', lines=True)\n",
    "\n",
    "program_answer_df.to_csv(output_dir / \"finqa_program_answer.csv\", index=False)\n",
    "program_answer_df.to_json(output_dir / \"finqa_program_answer.jsonl\", orient='records', lines=True)\n",
    "\n",
    "# Save train/dev splits separately\n",
    "train_final_answer.to_json(output_dir / \"finqa_final_answer_train.jsonl\", orient='records', lines=True)\n",
    "dev_final_answer.to_json(output_dir / \"finqa_final_answer_dev.jsonl\", orient='records', lines=True)\n",
    "\n",
    "train_program_answer.to_json(output_dir / \"finqa_program_answer_train.jsonl\", orient='records', lines=True)\n",
    "dev_program_answer.to_json(output_dir / \"finqa_program_answer_dev.jsonl\", orient='records', lines=True)\n",
    "\n",
    "# Print statistics about the processed datasets\n",
    "print(f\"\\nProcessed {len(final_answer_df)} examples for Objective A (Final Answer Only)\")\n",
    "print(f\"  - Train: {len(train_final_answer)} examples\")\n",
    "print(f\"  - Dev: {len(dev_final_answer)} examples\")\n",
    "\n",
    "print(f\"\\nProcessed {len(program_answer_df)} examples for Objective B (Program + Answer)\")\n",
    "print(f\"  - Train: {len(train_program_answer)} examples\")\n",
    "print(f\"  - Dev: {len(dev_program_answer)} examples\")\n",
    "\n",
    "print(f\"\\nAll processed datasets saved to {output_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FinQA Kernel",
   "language": "python",
   "name": "finqa-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
