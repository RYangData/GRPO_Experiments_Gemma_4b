{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyNd+UFAiv4B1JoBzb2C2QcA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"b13QBO0aHBNL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1742990767683,"user_tz":0,"elapsed":63812,"user":{"displayName":"Richard Y","userId":"09839538189249836074"}},"outputId":"ac049a4b-946a-4335-ff12-196997e76476"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Collecting unsloth\n","  Downloading unsloth-2025.3.18-py3-none-any.whl.metadata (46 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting vllm\n","  Downloading vllm-0.8.2-cp38-abi3-manylinux1_x86_64.whl.metadata (27 kB)\n","Downloading unsloth-2025.3.18-py3-none-any.whl (192 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.5/192.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading vllm-0.8.2-cp38-abi3-manylinux1_x86_64.whl (293.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.6/293.6 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: vllm, unsloth\n","Successfully installed unsloth-2025.3.18 vllm-0.8.2\n","Collecting git+https://github.com/huggingface/transformers@v4.49.0-Gemma-3\n","  Cloning https://github.com/huggingface/transformers (to revision v4.49.0-Gemma-3) to /tmp/pip-req-build-68cg_1e1\n","  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-68cg_1e1\n","  Running command git checkout -q 367bab469b0ef32017e2a0a0a5dbac5d36002f03\n","  Resolved https://github.com/huggingface/transformers to commit 367bab469b0ef32017e2a0a0a5dbac5d36002f03\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: transformers\n","  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for transformers: filename=transformers-4.50.0.dev0-py3-none-any.whl size=10936468 sha256=765456d8a2cca5118cbdd9e8ef318ad6c4d989fbed4566c0304082ab218d13bc\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-jxp3r56p/wheels/53/15/d5/d63b866c641d8863f9cd29a4cc7a5efc38476c3aae8247c195\n","Successfully built transformers\n","Installing collected packages: transformers\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.50.0\n","    Uninstalling transformers-4.50.0:\n","      Successfully uninstalled transformers-4.50.0\n","Successfully installed transformers-4.50.0.dev0\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# %%capture\n","import os\n","if \"COLAB_\" not in \"\".join(os.environ.keys()):\n","    !pip install unsloth vllm\n","else:\n","    # [NOTE] Do the below ONLY in Colab! Use [[pip install unsloth vllm]]\n","    !pip install --no-deps unsloth vllm\n","# Install latest Hugging Face for Gemma-3!\n","!pip install --no-deps git+https://github.com/huggingface/transformers@v4.49.0-Gemma-3"]},{"cell_type":"code","source":["!pip install bitsandbytes\n","!pip install unsloth_zoo\n","!pip install msgspec\n","!pip install blake3\n","!pip install gguf\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"HYgOWClAwf2C","executionInfo":{"status":"ok","timestamp":1742990860770,"user_tz":0,"elapsed":93081,"user":{"displayName":"Richard Y","userId":"09839538189249836074"}},"outputId":"153efa71-cca3-4620-e916-e40fa6d400cc"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting bitsandbytes\n","  Downloading bitsandbytes-0.45.4-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n","Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2025.3.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3,>=2.0->bitsandbytes)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3,>=2.0->bitsandbytes)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3,>=2.0->bitsandbytes)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3,>=2.0->bitsandbytes)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3,>=2.0->bitsandbytes)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3,>=2.0->bitsandbytes)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n","Downloading bitsandbytes-0.45.4-py3-none-manylinux_2_24_x86_64.whl (76.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m110.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m89.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bitsandbytes\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","unsloth 2025.3.18 requires datasets>=2.16.0, which is not installed.\n","unsloth 2025.3.18 requires hf_transfer, which is not installed.\n","unsloth 2025.3.18 requires trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9, which is not installed.\n","unsloth 2025.3.18 requires tyro, which is not installed.\n","unsloth 2025.3.18 requires unsloth_zoo>=2025.3.14, which is not installed.\n","unsloth 2025.3.18 requires xformers>=0.0.27.post2, which is not installed.\n","unsloth 2025.3.18 requires protobuf<4.0.0, but you have protobuf 5.29.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed bitsandbytes-0.45.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","Collecting unsloth_zoo\n","  Downloading unsloth_zoo-2025.3.16-py3-none-any.whl.metadata (8.0 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (2.6.0+cu124)\n","Requirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (3.2.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (24.2)\n","Collecting tyro (from unsloth_zoo)\n","  Downloading tyro-0.9.17-py3-none-any.whl.metadata (9.5 kB)\n","Requirement already satisfied: transformers!=4.47.0,>=4.46.1 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (4.50.0.dev0)\n","Collecting datasets>=2.16.0 (from unsloth_zoo)\n","  Downloading datasets-3.4.1-py3-none-any.whl.metadata (19 kB)\n","Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (0.2.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (4.67.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (5.9.5)\n","Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (0.45.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (2.0.2)\n","Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (1.5.2)\n","Collecting trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9 (from unsloth_zoo)\n","  Downloading trl-0.15.2-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (0.14.0)\n","Collecting protobuf<4.0.0 (from unsloth_zoo)\n","  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (0.29.3)\n","Collecting hf_transfer (from unsloth_zoo)\n","  Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n","Collecting cut_cross_entropy (from unsloth_zoo)\n","  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (11.1.0)\n","Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (2024.11.6)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.1->unsloth_zoo) (6.0.2)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.1->unsloth_zoo) (0.5.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->unsloth_zoo) (3.18.0)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->unsloth_zoo) (18.1.0)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.16.0->unsloth_zoo)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->unsloth_zoo) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->unsloth_zoo) (2.32.3)\n","Collecting xxhash (from datasets>=2.16.0->unsloth_zoo)\n","  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets>=2.16.0->unsloth_zoo)\n","  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=2.16.0->unsloth_zoo)\n","  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->unsloth_zoo) (3.11.14)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->unsloth_zoo) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->unsloth_zoo) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->unsloth_zoo) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->unsloth_zoo) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->unsloth_zoo) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->unsloth_zoo) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->unsloth_zoo) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->unsloth_zoo) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->unsloth_zoo) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->unsloth_zoo) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->unsloth_zoo) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->unsloth_zoo) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->unsloth_zoo) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->unsloth_zoo) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->unsloth_zoo) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->unsloth_zoo) (12.4.127)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->unsloth_zoo) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->unsloth_zoo) (1.3.0)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,>=4.46.1->unsloth_zoo) (0.21.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth_zoo) (13.9.4)\n","Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth_zoo) (0.16)\n","Collecting shtab>=1.5.6 (from tyro->unsloth_zoo)\n","  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n","Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth_zoo) (4.4.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->unsloth_zoo) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->unsloth_zoo) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->unsloth_zoo) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->unsloth_zoo) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->unsloth_zoo) (6.2.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->unsloth_zoo) (0.3.0)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->unsloth_zoo) (1.18.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth_zoo) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth_zoo) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth_zoo) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth_zoo) (2025.1.31)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth_zoo) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth_zoo) (2.18.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->unsloth_zoo) (3.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.16.0->unsloth_zoo) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.16.0->unsloth_zoo) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.16.0->unsloth_zoo) (2025.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth_zoo) (0.1.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth_zoo) (1.17.0)\n","Downloading unsloth_zoo-2025.3.16-py3-none-any.whl (126 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.9/126.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading datasets-3.4.1-py3-none-any.whl (487 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m487.4/487.4 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading trl-0.15.2-py3-none-any.whl (318 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n","Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m78.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tyro-0.9.17-py3-none-any.whl (123 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.7/123.7 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\n","Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: xxhash, shtab, protobuf, hf_transfer, fsspec, dill, multiprocess, tyro, datasets, cut_cross_entropy, trl, unsloth_zoo\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 5.29.4\n","    Uninstalling protobuf-5.29.4:\n","      Successfully uninstalled protobuf-5.29.4\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2025.3.0\n","    Uninstalling fsspec-2025.3.0:\n","      Successfully uninstalled fsspec-2025.3.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","unsloth 2025.3.18 requires xformers>=0.0.27.post2, which is not installed.\n","vllm 0.8.2 requires blake3, which is not installed.\n","vllm 0.8.2 requires compressed-tensors==0.9.2, which is not installed.\n","vllm 0.8.2 requires depyf==0.18.0, which is not installed.\n","vllm 0.8.2 requires fastapi[standard]>=0.115.0, which is not installed.\n","vllm 0.8.2 requires gguf==0.10.0, which is not installed.\n","vllm 0.8.2 requires lark==1.2.2, which is not installed.\n","vllm 0.8.2 requires llguidance<0.8.0,>=0.7.9; platform_machine == \"x86_64\" or platform_machine == \"arm64\" or platform_machine == \"aarch64\", which is not installed.\n","vllm 0.8.2 requires lm-format-enforcer<0.11,>=0.10.11, which is not installed.\n","vllm 0.8.2 requires mistral_common[opencv]>=1.5.4, which is not installed.\n","vllm 0.8.2 requires msgspec, which is not installed.\n","vllm 0.8.2 requires ninja, which is not installed.\n","vllm 0.8.2 requires outlines==0.1.11, which is not installed.\n","vllm 0.8.2 requires partial-json-parser, which is not installed.\n","vllm 0.8.2 requires prometheus-fastapi-instrumentator>=7.0.0, which is not installed.\n","vllm 0.8.2 requires python-json-logger, which is not installed.\n","vllm 0.8.2 requires ray[cgraph]>=2.43.0, which is not installed.\n","vllm 0.8.2 requires tiktoken>=0.6.0, which is not installed.\n","vllm 0.8.2 requires watchfiles, which is not installed.\n","vllm 0.8.2 requires xformers==0.0.29.post2; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","vllm 0.8.2 requires xgrammar==0.1.16; platform_machine == \"x86_64\" or platform_machine == \"aarch64\", which is not installed.\n","vllm 0.8.2 requires numpy<2.0.0, but you have numpy 2.0.2 which is incompatible.\n","grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\n","gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.12.0 which is incompatible.\n","tensorflow-metadata 1.16.1 requires protobuf<6.0.0dev,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed cut_cross_entropy-25.1.1 datasets-3.4.1 dill-0.3.8 fsspec-2024.12.0 hf_transfer-0.1.9 multiprocess-0.70.16 protobuf-3.20.3 shtab-1.7.1 trl-0.15.2 tyro-0.9.17 unsloth_zoo-2025.3.16 xxhash-3.5.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google"]},"id":"47873b460492467586abbc24aed05d23"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting msgspec\n","  Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n","Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (210 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: msgspec\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","vllm 0.8.2 requires blake3, which is not installed.\n","vllm 0.8.2 requires compressed-tensors==0.9.2, which is not installed.\n","vllm 0.8.2 requires depyf==0.18.0, which is not installed.\n","vllm 0.8.2 requires fastapi[standard]>=0.115.0, which is not installed.\n","vllm 0.8.2 requires gguf==0.10.0, which is not installed.\n","vllm 0.8.2 requires lark==1.2.2, which is not installed.\n","vllm 0.8.2 requires llguidance<0.8.0,>=0.7.9; platform_machine == \"x86_64\" or platform_machine == \"arm64\" or platform_machine == \"aarch64\", which is not installed.\n","vllm 0.8.2 requires lm-format-enforcer<0.11,>=0.10.11, which is not installed.\n","vllm 0.8.2 requires mistral_common[opencv]>=1.5.4, which is not installed.\n","vllm 0.8.2 requires ninja, which is not installed.\n","vllm 0.8.2 requires outlines==0.1.11, which is not installed.\n","vllm 0.8.2 requires partial-json-parser, which is not installed.\n","vllm 0.8.2 requires prometheus-fastapi-instrumentator>=7.0.0, which is not installed.\n","vllm 0.8.2 requires python-json-logger, which is not installed.\n","vllm 0.8.2 requires ray[cgraph]>=2.43.0, which is not installed.\n","vllm 0.8.2 requires tiktoken>=0.6.0, which is not installed.\n","vllm 0.8.2 requires watchfiles, which is not installed.\n","vllm 0.8.2 requires xformers==0.0.29.post2; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","vllm 0.8.2 requires xgrammar==0.1.16; platform_machine == \"x86_64\" or platform_machine == \"aarch64\", which is not installed.\n","vllm 0.8.2 requires numpy<2.0.0, but you have numpy 2.0.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed msgspec-0.19.0\n","Collecting blake3\n","  Downloading blake3-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n","Downloading blake3-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (376 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m376.2/376.2 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: blake3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","vllm 0.8.2 requires compressed-tensors==0.9.2, which is not installed.\n","vllm 0.8.2 requires depyf==0.18.0, which is not installed.\n","vllm 0.8.2 requires fastapi[standard]>=0.115.0, which is not installed.\n","vllm 0.8.2 requires gguf==0.10.0, which is not installed.\n","vllm 0.8.2 requires lark==1.2.2, which is not installed.\n","vllm 0.8.2 requires llguidance<0.8.0,>=0.7.9; platform_machine == \"x86_64\" or platform_machine == \"arm64\" or platform_machine == \"aarch64\", which is not installed.\n","vllm 0.8.2 requires lm-format-enforcer<0.11,>=0.10.11, which is not installed.\n","vllm 0.8.2 requires mistral_common[opencv]>=1.5.4, which is not installed.\n","vllm 0.8.2 requires ninja, which is not installed.\n","vllm 0.8.2 requires outlines==0.1.11, which is not installed.\n","vllm 0.8.2 requires partial-json-parser, which is not installed.\n","vllm 0.8.2 requires prometheus-fastapi-instrumentator>=7.0.0, which is not installed.\n","vllm 0.8.2 requires python-json-logger, which is not installed.\n","vllm 0.8.2 requires ray[cgraph]>=2.43.0, which is not installed.\n","vllm 0.8.2 requires tiktoken>=0.6.0, which is not installed.\n","vllm 0.8.2 requires watchfiles, which is not installed.\n","vllm 0.8.2 requires xformers==0.0.29.post2; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","vllm 0.8.2 requires xgrammar==0.1.16; platform_machine == \"x86_64\" or platform_machine == \"aarch64\", which is not installed.\n","vllm 0.8.2 requires numpy<2.0.0, but you have numpy 2.0.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed blake3-1.0.4\n","Collecting gguf\n","  Downloading gguf-0.14.0-py3-none-any.whl.metadata (3.7 kB)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from gguf) (2.0.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from gguf) (6.0.2)\n","Requirement already satisfied: sentencepiece<=0.2.0,>=0.1.98 in /usr/local/lib/python3.11/dist-packages (from gguf) (0.2.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from gguf) (4.67.1)\n","Downloading gguf-0.14.0-py3-none-any.whl (76 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.2/76.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: gguf\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","vllm 0.8.2 requires compressed-tensors==0.9.2, which is not installed.\n","vllm 0.8.2 requires depyf==0.18.0, which is not installed.\n","vllm 0.8.2 requires fastapi[standard]>=0.115.0, which is not installed.\n","vllm 0.8.2 requires lark==1.2.2, which is not installed.\n","vllm 0.8.2 requires llguidance<0.8.0,>=0.7.9; platform_machine == \"x86_64\" or platform_machine == \"arm64\" or platform_machine == \"aarch64\", which is not installed.\n","vllm 0.8.2 requires lm-format-enforcer<0.11,>=0.10.11, which is not installed.\n","vllm 0.8.2 requires mistral_common[opencv]>=1.5.4, which is not installed.\n","vllm 0.8.2 requires ninja, which is not installed.\n","vllm 0.8.2 requires outlines==0.1.11, which is not installed.\n","vllm 0.8.2 requires partial-json-parser, which is not installed.\n","vllm 0.8.2 requires prometheus-fastapi-instrumentator>=7.0.0, which is not installed.\n","vllm 0.8.2 requires python-json-logger, which is not installed.\n","vllm 0.8.2 requires ray[cgraph]>=2.43.0, which is not installed.\n","vllm 0.8.2 requires tiktoken>=0.6.0, which is not installed.\n","vllm 0.8.2 requires watchfiles, which is not installed.\n","vllm 0.8.2 requires xformers==0.0.29.post2; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","vllm 0.8.2 requires xgrammar==0.1.16; platform_machine == \"x86_64\" or platform_machine == \"aarch64\", which is not installed.\n","vllm 0.8.2 requires gguf==0.10.0, but you have gguf 0.14.0 which is incompatible.\n","vllm 0.8.2 requires numpy<2.0.0, but you have numpy 2.0.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed gguf-0.14.0\n"]}]},{"cell_type":"code","source":["# 1. Import required libraries\n","import json\n","import torch\n","from unsloth import FastModel\n","from transformers import TextStreamer\n","from pathlib import Path\n","import time\n","import re\n","\n","# 2. Define paths and settings\n","base_dir = \"/content/drive/MyDrive/2025_ConvFinQA_SFT_Agentic\"\n","# model_path =\n","model_path = \"/content/drive/MyDrive/2025_ConvFinQA_SFT_Agentic/gemma-3-25_03_26_11AM-final_answer\"\n","data_dir = Path(f\"{base_dir}/data/processed_datasets\")\n","dev_path = data_dir / \"finqa_final_answer_dev.jsonl\"\n","\n","# Toggle for verbose output - set to True to see all examples\n","VERBOSE_OUTPUT = True\n","\n","# Maximum number of examples to evaluate (set to None to evaluate all)\n","MAX_EXAMPLES: int | None = 100\n","\n","# 3. Load the fine-tuned model and tokenizer\n","print(\"Loading fine-tuned model...\")\n","model, tokenizer = FastModel.from_pretrained(\n","    model_name = model_path,\n","    max_seq_length = 4096,\n","    load_in_4bit = True,\n",")\n","\n","# 4. Set up the tokenizer with Gemma 3 chat template\n","from unsloth.chat_templates import get_chat_template\n","tokenizer = get_chat_template(\n","    tokenizer,\n","    chat_template = \"gemma-3\",\n",")\n","print(\"Model loaded successfully!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jIGIZ_Zu-g_g","executionInfo":{"status":"ok","timestamp":1742991401187,"user_tz":0,"elapsed":19097,"user":{"displayName":"Richard Y","userId":"09839538189249836074"}},"outputId":"a5e4bcef-5aa2-415d-cda5-821cac1d0fab"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading fine-tuned model...\n","==((====))==  Unsloth 2025.3.18: Fast Gemma3 patching. Transformers: 4.50.0.dev0. vLLM: 0.8.2.\n","   \\\\   /|    NVIDIA A100-SXM4-40GB. Num GPUs = 1. Max memory: 39.557 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.0. CUDA Toolkit: 12.4. Triton: 3.2.0\n","\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = False]\n"," \"-____-\"     Free license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","Model loaded successfully!\n"]}]},{"cell_type":"code","source":["\n","# 5. Load all dev examples\n","print(\"Loading development examples...\")\n","with open(dev_path, 'r') as f:\n","    dev_data = [json.loads(line) for line in f]\n","print(f\"Loaded {len(dev_data)} dev examples\")\n","\n","def test_model_on_example(example: dict, model, tokenizer) -> dict:\n","    \"\"\"Test the model on a single example using recommended Gemma 3 parameters\"\"\"\n","    # Create message format\n","    messages = [{\n","        \"role\": \"user\",\n","        \"content\": [{\n","            \"type\": \"text\",\n","            \"text\": example[\"prompt\"]\n","        }]\n","    }]\n","\n","    # Apply chat template\n","    text = tokenizer.apply_chat_template(\n","        messages,\n","        add_generation_prompt = True,\n","    )\n","\n","    # Generate response using recommended Gemma 3 parameters\n","    start_time = time.time()\n","    outputs = model.generate(\n","        **tokenizer([text], return_tensors=\"pt\").to(\"cuda\"),\n","        max_new_tokens = 128,  # Shorter for final answers\n","        temperature = 0.7,     # Lower temperature for more focused answers\n","        top_p = 0.95,         # Gemma 3 recommended\n","        top_k = 64,           # Gemma 3 recommended\n","    )\n","    end_time = time.time()\n","\n","    # Extract model output\n","    model_output = tokenizer.decode(outputs[0]).split(\"<start_of_turn>model\\n\")[1]\n","    if \"<end_of_turn>\" in model_output:\n","        model_output = model_output.split(\"<end_of_turn>\")[0]\n","\n","    generation_time = end_time - start_time\n","\n","    return {\n","        \"model_output\": model_output.strip(),\n","        \"expected_output\": example[\"answer\"],\n","        \"generation_time\": generation_time,\n","        \"prompt\": example[\"prompt\"]\n","    }\n","\n","def is_numeric_match(expected: str, generated: str) -> bool:\n","    \"\"\"Check if numbers in the answers match, including handling rounding differences\"\"\"\n","    try:\n","        # Convert percentage strings to floats\n","        expected_num = float(expected.strip('%')) if '%' in expected else float(expected)\n","        generated_num = float(generated.strip('%')) if '%' in generated else float(generated)\n","\n","        # If both are percentages or both are not percentages\n","        if ('%' in expected) == ('%' in generated):\n","            # For percentages, allow 0.2 percentage point difference\n","            if '%' in expected:\n","                return abs(expected_num - generated_num) <= 0.2\n","            # For non-percentages, allow 1% relative difference\n","            else:\n","                relative_diff = abs(expected_num - generated_num) / max(abs(expected_num), 0.0001)\n","                return relative_diff < 0.01\n","        return False\n","    except ValueError:\n","        return False\n","\n","# Run evaluation\n","print(\"\\n\" + \"=\"*80)\n","print(\"RUNNING FINAL ANSWER EVALUATION\")\n","print(\"=\"*80)\n","\n","if VERBOSE_OUTPUT:\n","    print(\"Verbose output enabled - showing all examples\")\n","else:\n","    print(\"Verbose output disabled - showing summary only\")\n","\n","# Track metrics\n","all_results = []\n","total_time = 0\n","exact_match_count = 0\n","numeric_match_count = 0\n","\n","# Run evaluation\n","dev_data_to_evaluate = dev_data[:MAX_EXAMPLES] if MAX_EXAMPLES is not None else dev_data\n","total_examples = len(dev_data_to_evaluate)\n","print(f\"Starting evaluation on {total_examples} examples...\")\n","\n","# Create output file for all predictions\n","predictions_file = f\"{base_dir}/evaluation_outputs/final_answer_predictions.jsonl\"\n","with open(predictions_file, 'w') as pred_file:\n","    for i, example in enumerate(dev_data_to_evaluate):\n","        # Print progress updates\n","        if not VERBOSE_OUTPUT and ((i+1) % 25 == 0 or i+1 == total_examples):\n","            print(f\"Progress: {i+1}/{total_examples} examples evaluated\")\n","\n","        # Run the model on this example\n","        result = test_model_on_example(example, model, tokenizer)\n","\n","        # Clean up answers for comparison\n","        expected_answer = result[\"expected_output\"].strip()\n","        model_answer = result[\"model_output\"].strip()\n","\n","        # Check for exact match\n","        exact_match = expected_answer.lower() == model_answer.lower()\n","        if exact_match:\n","            exact_match_count += 1\n","            match_status = \"exact\"\n","        else:\n","            # Check for numeric match with improved tolerance\n","            numeric_match = is_numeric_match(expected_answer, model_answer)\n","            if numeric_match:\n","                numeric_match_count += 1\n","                match_status = \"numeric\"\n","            else:\n","                match_status = \"incorrect\"\n","\n","        # Save results\n","        result[\"exact_match\"] = exact_match\n","        result[\"numeric_match\"] = numeric_match\n","        result[\"match_status\"] = match_status\n","\n","        all_results.append(result)\n","        total_time += result[\"generation_time\"]\n","\n","        # Write individual result to JSONL file\n","        pred_file.write(json.dumps({\n","            \"id\": example.get(\"id\", f\"example_{i}\"),\n","            \"expected_answer\": expected_answer,\n","            \"model_answer\": model_answer,\n","            \"exact_match\": exact_match,\n","            \"numeric_match\": numeric_match,\n","            \"match_status\": match_status,\n","        }) + \"\\n\")\n","\n","        # Print verbose output if enabled\n","        if VERBOSE_OUTPUT:\n","            print(f\"\\n{'-'*80}\")\n","            print(f\"Example {i+1}/{total_examples} [{match_status.upper()}]\")\n","            print(f\"Expected: {expected_answer}\")\n","            print(f\"Model: {model_answer}\")\n","            print(f\"Generation time: {result['generation_time']:.2f} seconds\")\n","\n","# Calculate and print evaluation metrics\n","avg_generation_time = total_time / total_examples\n","exact_match_accuracy = (exact_match_count / total_examples) * 100\n","numeric_match_accuracy = ((exact_match_count + numeric_match_count) / total_examples) * 100\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"EVALUATION RESULTS\")\n","print(\"=\"*80)\n","print(f\"Total examples evaluated: {total_examples}\")\n","print(f\"Average generation time: {avg_generation_time:.2f} seconds\")\n","print(f\"Exact match accuracy: {exact_match_accuracy:.2f}%\")\n","print(f\"Numeric match accuracy (includes exact + approximate): {numeric_match_accuracy:.2f}%\")\n","print(f\"Exact matches: {exact_match_count}/{total_examples}\")\n","print(f\"Numeric-only matches: {numeric_match_count}/{total_examples}\")\n","\n","# Save detailed results to JSON\n","results_file = f\"{base_dir}/evaluation_outputs/final_answer_evaluation_results.json\"\n","with open(results_file, 'w') as f:\n","    json.dump({\n","        \"summary\": {\n","            \"total_examples\": total_examples,\n","            \"exact_match_accuracy\": exact_match_accuracy,\n","            \"numeric_match_accuracy\": numeric_match_accuracy,\n","            \"exact_match_count\": exact_match_count,\n","            \"numeric_match_count\": numeric_match_count,\n","            \"avg_generation_time\": avg_generation_time,\n","        },\n","        \"results\": [{\n","            \"expected_answer\": r[\"expected_output\"],\n","            \"model_answer\": r[\"model_output\"],\n","            \"match_status\": r[\"match_status\"],\n","            \"generation_time\": r[\"generation_time\"]\n","        } for r in all_results]\n","    }, f, indent=2)\n","\n","print(f\"\\nDetailed results saved to {results_file}\")\n","print(\"\\nEvaluation complete!\")"],"metadata":{"id":"xdLO6Tcb-g9r","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1742991524765,"user_tz":0,"elapsed":123574,"user":{"displayName":"Richard Y","userId":"09839538189249836074"}},"outputId":"e6cef542-0b4c-42a6-e360-0c12d6c1b28e"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading development examples...\n","Loaded 542 dev examples\n","\n","================================================================================\n","RUNNING FINAL ANSWER EVALUATION\n","================================================================================\n","Verbose output enabled - showing all examples\n","Starting evaluation on 100 examples...\n","\n","--------------------------------------------------------------------------------\n","Example 1/100 [INCORRECT]\n","Expected: 142.4%\n","Model: 134.8%\n","Generation time: 28.37 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 2/100 [INCORRECT]\n","Expected: -21.1%\n","Model: -16%\n","Generation time: 0.94 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 3/100 [INCORRECT]\n","Expected: 37.5%\n","Model: -21.4%\n","Generation time: 1.31 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 4/100 [INCORRECT]\n","Expected: 10.83%\n","Model: 11.1%\n","Generation time: 1.11 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 5/100 [INCORRECT]\n","Expected: -10%\n","Model: -8.8%\n","Generation time: 1.08 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 6/100 [EXACT]\n","Expected: 4\n","Model: 4\n","Generation time: 0.40 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 7/100 [INCORRECT]\n","Expected: 14\n","Model: 0.1\n","Generation time: 0.72 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 8/100 [INCORRECT]\n","Expected: 257\n","Model: 2562\n","Generation time: 0.88 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 9/100 [INCORRECT]\n","Expected: 12.6%\n","Model: 13.5%\n","Generation time: 1.06 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 10/100 [INCORRECT]\n","Expected: 11%\n","Model: 11.5%\n","Generation time: 1.06 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 11/100 [INCORRECT]\n","Expected: 24.69%\n","Model: 25%\n","Generation time: 0.71 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 12/100 [NUMERIC]\n","Expected: 1.7%\n","Model: 1.5%\n","Generation time: 0.90 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 13/100 [INCORRECT]\n","Expected: 1877\n","Model: 29.05\n","Generation time: 1.05 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 14/100 [INCORRECT]\n","Expected: 7.51%\n","Model: 11.5%\n","Generation time: 1.14 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 15/100 [INCORRECT]\n","Expected: 8%\n","Model: 11.5%\n","Generation time: 1.08 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 16/100 [EXACT]\n","Expected: 688\n","Model: 688\n","Generation time: 0.73 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 17/100 [EXACT]\n","Expected: 7.0\n","Model: 7.0\n","Generation time: 0.72 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 18/100 [INCORRECT]\n","Expected: 1.4%\n","Model: 1.1%\n","Generation time: 0.89 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 19/100 [INCORRECT]\n","Expected: 37.7%\n","Model: 36.5%\n","Generation time: 1.07 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 20/100 [INCORRECT]\n","Expected: 62.9%\n","Model: 65.5%\n","Generation time: 1.08 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 21/100 [INCORRECT]\n","Expected: 2525\n","Model: 2.5\n","Generation time: 0.73 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 22/100 [INCORRECT]\n","Expected: 3.85\n","Model: 2.1\n","Generation time: 0.73 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 23/100 [INCORRECT]\n","Expected: 44%\n","Model: 118.2%\n","Generation time: 1.24 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 24/100 [INCORRECT]\n","Expected: 29.3%\n","Model: 15.5%\n","Generation time: 1.12 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 25/100 [INCORRECT]\n","Expected: 1041.5\n","Model: 170.6\n","Generation time: 1.08 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 26/100 [INCORRECT]\n","Expected: 38.2%\n","Model: -38.5%\n","Generation time: 1.23 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 27/100 [EXACT]\n","Expected: 5.5%\n","Model: 5.5%\n","Generation time: 0.90 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 28/100 [EXACT]\n","Expected: 104\n","Model: 104\n","Generation time: 0.73 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 29/100 [INCORRECT]\n","Expected: 7.51%\n","Model: 10.1%\n","Generation time: 1.09 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 30/100 [INCORRECT]\n","Expected: 2672\n","Model: 1384\n","Generation time: 0.94 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 31/100 [INCORRECT]\n","Expected: 38.7%\n","Model: 3.9%\n","Generation time: 0.91 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 32/100 [INCORRECT]\n","Expected: 0.94\n","Model: 1.15\n","Generation time: 0.90 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 33/100 [EXACT]\n","Expected: -13.2\n","Model: -13.2\n","Generation time: 1.07 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 34/100 [INCORRECT]\n","Expected: 8.3%\n","Model: 10.7%\n","Generation time: 1.07 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 35/100 [INCORRECT]\n","Expected: 7.22\n","Model: 18.5\n","Generation time: 0.88 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 36/100 [INCORRECT]\n","Expected: -7.4%\n","Model: -8.1%\n","Generation time: 1.07 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 37/100 [INCORRECT]\n","Expected: 738.5\n","Model: 981\n","Generation time: 0.72 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 38/100 [INCORRECT]\n","Expected: 4.27\n","Model: 10.3\n","Generation time: 0.88 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 39/100 [INCORRECT]\n","Expected: -3.4%\n","Model: -2.1%\n","Generation time: 1.06 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 40/100 [EXACT]\n","Expected: 93.5%\n","Model: 93.5%\n","Generation time: 1.05 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 41/100 [INCORRECT]\n","Expected: 13.4%\n","Model: 6.1%\n","Generation time: 0.88 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 42/100 [INCORRECT]\n","Expected: 1.56%\n","Model: -15.1%\n","Generation time: 1.22 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 43/100 [INCORRECT]\n","Expected: 0.88\n","Model: 16\n","Generation time: 0.55 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 44/100 [INCORRECT]\n","Expected: 25.9%\n","Model: 18.5%\n","Generation time: 1.04 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 45/100 [INCORRECT]\n","Expected: -21.08%\n","Model: 78.92%\n","Generation time: 1.22 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 46/100 [INCORRECT]\n","Expected: 3.4%\n","Model: -3.1%\n","Generation time: 1.13 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 47/100 [INCORRECT]\n","Expected: 65%\n","Model: 1.6%\n","Generation time: 0.89 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 48/100 [INCORRECT]\n","Expected: 2.37\n","Model: 2.3\n","Generation time: 0.71 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 49/100 [NUMERIC]\n","Expected: -1.2%\n","Model: -1.1%\n","Generation time: 1.04 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 50/100 [INCORRECT]\n","Expected: 0.5%\n","Model: 1.7%\n","Generation time: 0.87 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 51/100 [INCORRECT]\n","Expected: 6%\n","Model: 6.4%\n","Generation time: 0.88 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 52/100 [INCORRECT]\n","Expected: -135\n","Model: -1110\n","Generation time: 1.04 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 53/100 [NUMERIC]\n","Expected: 1.3%\n","Model: 1.5%\n","Generation time: 0.89 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 54/100 [EXACT]\n","Expected: 44.8\n","Model: 44.8\n","Generation time: 0.89 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 55/100 [EXACT]\n","Expected: 37.81%\n","Model: 37.81%\n","Generation time: 1.24 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 56/100 [INCORRECT]\n","Expected: 3.6%\n","Model: 2.5%\n","Generation time: 0.92 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 57/100 [INCORRECT]\n","Expected: 6.8%\n","Model: -11.1%\n","Generation time: 1.25 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 58/100 [INCORRECT]\n","Expected: 20.7\n","Model: 21.1\n","Generation time: 0.88 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 59/100 [INCORRECT]\n","Expected: 47.6%\n","Model: 3655945\n","Generation time: 1.38 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 60/100 [EXACT]\n","Expected: 88%\n","Model: 88%\n","Generation time: 0.72 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 61/100 [NUMERIC]\n","Expected: -1.3%\n","Model: -1.1%\n","Generation time: 1.05 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 62/100 [EXACT]\n","Expected: 2.25\n","Model: 2.25\n","Generation time: 0.88 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 63/100 [NUMERIC]\n","Expected: 9.9%\n","Model: 10.1%\n","Generation time: 1.06 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 64/100 [INCORRECT]\n","Expected: 4%\n","Model: 3.5%\n","Generation time: 0.89 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 65/100 [INCORRECT]\n","Expected: 20%\n","Model: 28%\n","Generation time: 0.71 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 66/100 [INCORRECT]\n","Expected: -35.6%\n","Model: -31.5%\n","Generation time: 1.26 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 67/100 [INCORRECT]\n","Expected: -12.4%\n","Model: -10.0%\n","Generation time: 1.26 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 68/100 [INCORRECT]\n","Expected: 4\n","Model: -1\n","Generation time: 0.55 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 69/100 [INCORRECT]\n","Expected: 33.3%\n","Model: 16.7%\n","Generation time: 1.06 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 70/100 [INCORRECT]\n","Expected: 6.88\n","Model: 6.8\n","Generation time: 0.74 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 71/100 [INCORRECT]\n","Expected: 9.41\n","Model: 10.1\n","Generation time: 0.90 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 72/100 [INCORRECT]\n","Expected: 8.04%\n","Model: -8.3%\n","Generation time: 1.08 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 73/100 [NUMERIC]\n","Expected: 4.41%\n","Model: 4.3%\n","Generation time: 0.89 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 74/100 [INCORRECT]\n","Expected: 8.53%\n","Model: 1.3\n","Generation time: 0.72 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 75/100 [EXACT]\n","Expected: -3.5%\n","Model: -3.5%\n","Generation time: 1.08 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 76/100 [INCORRECT]\n","Expected: 965.6\n","Model: 106.5\n","Generation time: 1.08 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 77/100 [INCORRECT]\n","Expected: 1041.5\n","Model: 170.6\n","Generation time: 1.08 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 78/100 [INCORRECT]\n","Expected: 46.3\n","Model: 10000\n","Generation time: 1.10 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 79/100 [INCORRECT]\n","Expected: 75.6%\n","Model: 78%\n","Generation time: 0.73 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 80/100 [INCORRECT]\n","Expected: 1.4%\n","Model: 1.1%\n","Generation time: 0.91 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 81/100 [INCORRECT]\n","Expected: 3.8%\n","Model: 11.7%\n","Generation time: 1.07 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 82/100 [INCORRECT]\n","Expected: 6.8%\n","Model: 4.9\n","Generation time: 0.71 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 83/100 [INCORRECT]\n","Expected: 73.4%\n","Model: -10.5%\n","Generation time: 1.23 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 84/100 [INCORRECT]\n","Expected: 1798334\n","Model: 171.5\n","Generation time: 1.06 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 85/100 [INCORRECT]\n","Expected: 1300\n","Model: 1.3\n","Generation time: 0.72 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 86/100 [INCORRECT]\n","Expected: 5583331\n","Model: 1.71\n","Generation time: 0.88 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 87/100 [INCORRECT]\n","Expected: 56\n","Model: 1.1\n","Generation time: 0.72 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 88/100 [INCORRECT]\n","Expected: 1.7%\n","Model: 10.5%\n","Generation time: 1.08 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 89/100 [INCORRECT]\n","Expected: 5.8%\n","Model: 56.3%\n","Generation time: 1.11 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 90/100 [INCORRECT]\n","Expected: 1798334\n","Model: 171.5\n","Generation time: 1.07 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 91/100 [EXACT]\n","Expected: 1.7\n","Model: 1.7\n","Generation time: 0.73 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 92/100 [EXACT]\n","Expected: 13%\n","Model: 13%\n","Generation time: 0.72 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 93/100 [INCORRECT]\n","Expected: 24%\n","Model: 23.1%\n","Generation time: 1.07 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 94/100 [INCORRECT]\n","Expected: 18068.8\n","Model: 29.1\n","Generation time: 0.90 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 95/100 [EXACT]\n","Expected: 3.5%\n","Model: 3.5%\n","Generation time: 0.89 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 96/100 [INCORRECT]\n","Expected: -3.2%\n","Model: 1.6%\n","Generation time: 0.91 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 97/100 [INCORRECT]\n","Expected: 3044%\n","Model: 32.5%\n","Generation time: 1.09 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 98/100 [EXACT]\n","Expected: no\n","Model: no\n","Generation time: 0.40 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 99/100 [INCORRECT]\n","Expected: 2.9%\n","Model: 3.3%\n","Generation time: 0.91 seconds\n","\n","--------------------------------------------------------------------------------\n","Example 100/100 [NUMERIC]\n","Expected: 1521.55\n","Model: 1516.8\n","Generation time: 1.24 seconds\n","\n","================================================================================\n","EVALUATION RESULTS\n","================================================================================\n","Total examples evaluated: 100\n","Average generation time: 1.23 seconds\n","Exact match accuracy: 16.00%\n","Numeric match accuracy (includes exact + approximate): 23.00%\n","Exact matches: 16/100\n","Numeric-only matches: 7/100\n","\n","Detailed results saved to /content/drive/MyDrive/2025_ConvFinQA_SFT_Agentic/evaluation_outputs/final_answer_evaluation_results.json\n","\n","Evaluation complete!\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"3Nuq33ZO-g7m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"QTSb6wlD-g5R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"hLtsMBpu-g27"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"pebqUuUW-g0k"},"execution_count":null,"outputs":[]}]}